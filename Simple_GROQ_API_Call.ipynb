{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1zmfpzNUVdNWjpvM0o5PZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lekejo/lekejo/blob/main/Simple_GROQ_API_Call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq openai python-dotenv\n",
        "!pip install google-cloud-secret-manager"
      ],
      "metadata": {
        "id": "mFUV7aXITPS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fNqxmtlSvsr",
        "outputId": "aa4842b3-990e-4aa7-970a-2be0cf9498ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            " Tell me a joke\n",
            "\n",
            "Response:\n",
            " Why was the math book sad? Because it had too many problems.\n",
            "\n",
            "I'm just a simple AI and my humor might be a bit dry, but I hope it brought a tiny smile to your face! If you need any more jokes or assistance with anything else, feel free to ask.\n",
            "\n",
            "Total Inference Time Plus Network: 0.5560333728790283 seconds\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Quick Prompt Module\n",
        "\"\"\"\n",
        "import os\n",
        "import time\n",
        "from groq import Groq\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "#local machine\n",
        "#client = Groq(\n",
        "#  api_key=os.environ.get(\"GROQ_API_KEY\")\n",
        "#)\n",
        "\n",
        "# google colab\n",
        "client = Groq(\n",
        "  api_key=userdata.get('GROQ_API_KEY')\n",
        ")\n",
        "\n",
        "def main():\n",
        "  prompt = \"Tell me a joke\"\n",
        "  start_time = time.time()\n",
        "  chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"{prompt}\"\n",
        "      }\n",
        "    ],\n",
        "    model=\"mixtral-8x7b-32768\"\n",
        "  )\n",
        "\n",
        "  print(f\"Prompt:\\n {prompt}\\n\")\n",
        "  print(f\"Response:\\n {chat_completion.choices[0].message.content}\\n\")\n",
        "\n",
        "  end_time = time.time()\n",
        "  print(f\"Total Inference Time Plus Network: {end_time-start_time} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ]
}